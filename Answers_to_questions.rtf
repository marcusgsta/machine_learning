{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;\f1\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red38\green38\blue38;\red233\green233\blue233;\red0\green0\blue0;
\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c20000\c20000\c20000;\cssrgb\c92941\c92941\c92941;\cssrgb\c0\c0\c0;
\cssrgb\c100000\c100000\c100000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl360\partightenfactor0
\ls1\ilvl0
\f0\fs32 \cf2 \cb3 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Why is the accuracy of the Linear classifier very low compared to the Neural Network classifier?\
\pard\tx566\pardeftab720\sl360\partightenfactor0
\cf2 \cb1 \
The classifiers try to divide the vectors in the dataset according to their classification. If the dataset has a distribution so that you can draw a straight line between the dots in the graph, then a linear classifier could make a good prediction.\
\
This dataset is in a spiral form, so in order to divide the vector points we can imagine a line that is bending inside the spiral, in best case creating perfect divisions between the three classes. This type of division can only be done by a more complex, Neural Network classifier. It recalculates the weights (?) and iterates again, with the help of hidden layers. \
\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl360\partightenfactor0
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Write code to show the confusion matrix for both the Linear and Neural Network classifier\
\pard\tx566\pardeftab720\sl360\partightenfactor0
\cf2 \cb1 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl360\partightenfactor0
\ls3\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 How shall the confusion matrix be interpreted? What does it tell us that the accuracy metric doesn\'92t?\cb1 \
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\pard\tx566\pardeftab720\sl360\partightenfactor0
\cf2 \
It not only tells us how many points were correctly classified. It also tells us how many point were classified falsely. This is important\
It gives us True Positives, False Positives, True Negatives and False Negatives.\
\
The accuracy metric only measures what percentage of the predictions were correct. \
\
\pard\pardeftab720\sl320\partightenfactor0

\f1\fs28 \cf4 \cb5 \strokec4 [[18  0  1]\
 [ 0 20  0]\
 [ 0  0 21]]\
\pard\tx566\pardeftab720\sl360\partightenfactor0

\f0\fs32 \cf2 \cb1 \strokec2 \
This means that \
Confusion Matrix can be good in order to see if the system is confusing two classes - commonly mislabeling one as another. In the above matrix, only class \'922\'92 had an error - one instance where the algorithm predicted class \'920\'92.\
\
\pard\pardeftab720\sl320\partightenfactor0

\f1\fs28 \cf4 \cb5 \strokec4 [[ 5  0 14]\
 [ 0 11  9]\
 [ 0  0 21]]\
\pard\tx566\pardeftab720\sl360\partightenfactor0

\f0\fs32 \cf2 \cb1 \strokec2 \
In this matrix for the Linear Classifier, class 0 and 1 were perfectly predicted, while class 2 had a quite low accuracy. So, class 2 was the most difficult to predict in this case.\
\
\'85\
\
Results from MNIST training with ConvNet.\
\
\pard\pardeftab720\sl320\partightenfactor0

\f1\fs28 \cf4 \cb5 \strokec4 Train on 60000 samples, validate on 10000 samples\
Epoch 1/10\
60000/60000 [==============================] - 193s 3ms/step - loss: 0.7815 - acc: 0.9179 - val_loss: 0.0828 - val_acc: 0.9757\
Epoch 2/10\
60000/60000 [==============================] - 196s 3ms/step - loss: 0.0666 - acc: 0.9800 - val_loss: 0.0750 - val_acc: 0.9776\
Epoch 3/10\
60000/60000 [==============================] - 203s 3ms/step - loss: 0.0485 - acc: 0.9843 - val_loss: 0.0823 - val_acc: 0.9757\
Epoch 4/10\
60000/60000 [==============================] - 178s 3ms/step - loss: 0.0332 - acc: 0.9892 - val_loss: 0.0915 - val_acc: 0.9753\
Epoch 5/10\
60000/60000 [==============================] - 186s 3ms/step - loss: 0.0247 - acc: 0.9918 - val_loss: 0.1268 - val_acc: 0.9733\
Epoch 6/10\
60000/60000 [==============================] - 187s 3ms/step - loss: 0.0258 - acc: 0.9920 - val_loss: 0.1154 - val_acc: 0.9731\
Epoch 7/10\
60000/60000 [==============================] - 188s 3ms/step - loss: 0.0181 - acc: 0.9947 - val_loss: 0.1242 - val_acc: 0.9792\
Epoch 8/10\
60000/60000 [==============================] - 178s 3ms/step - loss: 0.0211 - acc: 0.9939 - val_loss: 0.1108 - val_acc: 0.9782\
Epoch 9/10\
60000/60000 [==============================] - 177s 3ms/step - loss: 0.0181 - acc: 0.9950 - val_loss: 0.1543 - val_acc: 0.9754\
Epoch 10/10\
60000/60000 [==============================] - 178s 3ms/step - loss: 0.0133 - acc: 0.9962 - val_loss: 0.1488 - val_acc: 0.9757\
CPU times: user 1h 21min 49s, sys: 5min 45s, total: 1h 27min 35s\
Wall time: 31min 5s\
\pard\tx566\pardeftab720\sl360\partightenfactor0

\f0\fs32 \cf2 \cb1 \strokec2 \
\
MNIST TRAINING WITH LINEAR CLASSIFIER\
just the output layer Dense\
\
\pard\pardeftab720\sl320\partightenfactor0

\f1\fs28 \cf4 \cb5 \strokec4 Train on 60000 samples, validate on 10000 samples\
Epoch 1/15\
60000/60000 [==============================] - 10s 159us/step - loss: 7.1042 - acc: 0.5535 - val_loss: 6.4391 - val_acc: 0.5966\
Epoch 2/15\
60000/60000 [==============================] - 7s 123us/step - loss: 6.1845 - acc: 0.6131 - val_loss: 6.0716 - val_acc: 0.6208\
Epoch 3/15\
60000/60000 [==============================] - 8s 129us/step - loss: 5.1225 - acc: 0.6790 - val_loss: 4.9681 - val_acc: 0.6878\
Epoch 4/15\
60000/60000 [==============================] - 8s 130us/step - loss: 4.7617 - acc: 0.7020 - val_loss: 4.7194 - val_acc: 0.7045\
Epoch 5/15\
60000/60000 [==============================] - 8s 134us/step - loss: 4.8034 - acc: 0.6998 - val_loss: 4.7476 - val_acc: 0.7036\
Epoch 6/15\
60000/60000 [==============================] - 8s 133us/step - loss: 4.7404 - acc: 0.7037 - val_loss: 4.5894 - val_acc: 0.7134\
Epoch 7/15\
60000/60000 [==============================] - 8s 136us/step - loss: 4.6676 - acc: 0.7087 - val_loss: 4.7823 - val_acc: 0.7012\
Epoch 8/15\
60000/60000 [==============================] - 9s 142us/step - loss: 4.6859 - acc: 0.7075 - val_loss: 4.5605 - val_acc: 0.7152\
Epoch 9/15\
60000/60000 [==============================] - 8s 127us/step - loss: 4.7150 - acc: 0.7055 - val_loss: 4.9122 - val_acc: 0.6934\
Epoch 10/15\
60000/60000 [==============================] - 8s 134us/step - loss: 4.6380 - acc: 0.7108 - val_loss: 4.5661 - val_acc: 0.7156\
Epoch 11/15\
60000/60000 [==============================] - 8s 127us/step - loss: 4.6662 - acc: 0.7093 - val_loss: 4.5438 - val_acc: 0.7172\
Epoch 12/15\
60000/60000 [==============================] - 8s 139us/step - loss: 4.6261 - acc: 0.7118 - val_loss: 4.5194 - val_acc: 0.7182\
Epoch 13/15\
60000/60000 [==============================] - 8s 137us/step - loss: 4.5942 - acc: 0.7135 - val_loss: 4.6366 - val_acc: 0.7114\
Epoch 14/15\
60000/60000 [==============================] - 8s 128us/step - loss: 4.6243 - acc: 0.7121 - val_loss: 4.6430 - val_acc: 0.7111\
Epoch 15/15\
60000/60000 [==============================] - 8s 126us/step - loss: 4.6202 - acc: 0.7123 - val_loss: 4.4972 - val_acc: 0.7196\
CPU times: user 3min 58s, sys: 21.8 s, total: 4min 20s\
Wall time: 2min\
\pard\tx566\pardeftab720\sl360\partightenfactor0

\f0\fs32 \cf2 \cb1 \strokec2 \
\
}